#!/usr/bin/env python3
"""
ì—°í•©í•™ìŠµ ìµœì¢… ëª¨ë¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ (ìƒì„¸ í‰ê°€ ë²„ì „)
"""

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import transforms
import numpy as np
from sklearn.metrics import confusion_matrix
from tqdm import tqdm

from iot_fed.task import Net
from iot_fed.dataset import SkinDiseaseDataset


def load_model(checkpoint_path: str, device: torch.device):
    """
    ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ ë¡œë“œ

    Args:
        checkpoint_path: ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ
        device: ë””ë°”ì´ìŠ¤

    Returns:
        model: ë¡œë“œëœ ëª¨ë¸
        checkpoint_info: ì²´í¬í¬ì¸íŠ¸ ë©”íƒ€ë°ì´í„°
    """
    print(f"Loading checkpoint from: {checkpoint_path}")
    checkpoint = torch.load(checkpoint_path, map_location=device)

    # ëª¨ë¸ ìƒì„±
    model = Net(num_classes=6, pretrained=False, drop_rate=0.2)

    # ê°€ì¤‘ì¹˜ ë¡œë“œ
    checkpoint_info = {}
    if isinstance(checkpoint, dict) and "model_state_dict" in checkpoint:
        state_dict = checkpoint["model_state_dict"]
        checkpoint_info = {
            'epoch': checkpoint.get('epoch', 'N/A'),
            'train_acc': checkpoint.get('train_acc', 'N/A'),
            'val_acc': checkpoint.get('val_acc', 'N/A')
        }
    else:
        # ì§ì ‘ state_dictì¸ ê²½ìš° (final_model.pt ë“±)
        state_dict = checkpoint

    # í‚¤ í˜•ì‹ ë³€í™˜ (í•„ìš”ì‹œ)
    if state_dict:
        first_key = next(iter(state_dict.keys()))
        # best_model.pth: 'conv_stem.weight' â†’ 'model.conv_stem.weight' ë³€í™˜ í•„ìš”
        if not first_key.startswith('model.'):
            print("   â„¹ï¸  state_dict í‚¤ì— 'model.' ì ‘ë‘ì‚¬ ì¶”ê°€ ì¤‘...")
            state_dict = {f'model.{k}': v for k, v in state_dict.items()}
        # final_model.pt: 'model.conv_stem.weight' â†’ ê·¸ëŒ€ë¡œ ì‚¬ìš©

    model.load_state_dict(state_dict)
    model = model.to(device)
    model.eval()

    print("   âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
    if checkpoint_info:
        if checkpoint_info['epoch'] != 'N/A':
            print(f"   âœ“ Epoch: {checkpoint_info['epoch']}")
        if checkpoint_info['train_acc'] != 'N/A':
            print(f"   âœ“ Train Acc: {checkpoint_info['train_acc']:.2f}%")
        if checkpoint_info['val_acc'] != 'N/A':
            print(f"   âœ“ Val Acc: {checkpoint_info['val_acc']:.2f}%")

    return model, checkpoint_info


def evaluate(model, dataloader, criterion, device, class_names):
    """
    ëª¨ë¸ í‰ê°€ (ìƒì„¸ ë²„ì „)

    Args:
        model: í‰ê°€í•  ëª¨ë¸
        dataloader: Validation DataLoader
        criterion: Loss í•¨ìˆ˜
        device: ë””ë°”ì´ìŠ¤
        class_names: í´ë˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸

    Returns:
        dict: í‰ê°€ ê²°ê³¼
    """
    model.eval()
    running_loss = 0.0
    all_preds = []
    all_labels = []

    print("Starting evaluation...")

    with torch.no_grad():
        pbar = tqdm(dataloader, desc="ğŸ” í‰ê°€ ì¤‘", unit="batch")
        for images, labels in pbar:
            images = images.to(device)
            labels = labels.to(device)

            # Forward
            outputs = model(images)
            loss = criterion(outputs, labels)

            # Metrics
            running_loss += loss.item()
            _, predicted = outputs.max(1)

            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

            # Progress bar ì—…ë°ì´íŠ¸
            current_acc = sum(np.array(all_preds) == np.array(all_labels)) / len(all_labels)
            pbar.set_postfix({'loss': running_loss / (pbar.n + 1), 'acc': f'{current_acc:.4f}'})

    # ì „ì²´ í†µê³„
    val_loss = running_loss / len(dataloader)
    all_preds = np.array(all_preds)
    all_labels = np.array(all_labels)
    accuracy = 100.0 * (all_preds == all_labels).sum() / len(all_labels)

    # í´ë˜ìŠ¤ë³„ ì •í™•ë„
    per_class_acc = {}
    for idx, class_name in enumerate(class_names):
        mask = all_labels == idx
        if mask.sum() > 0:
            class_acc = 100.0 * (all_preds[mask] == all_labels[mask]).sum() / mask.sum()
            per_class_acc[class_name] = {
                'accuracy': class_acc,
                'correct': int((all_preds[mask] == all_labels[mask]).sum()),
                'total': int(mask.sum())
            }

    # Confusion Matrix
    cm = confusion_matrix(all_labels, all_preds)

    return {
        'loss': val_loss,
        'accuracy': accuracy,
        'per_class_acc': per_class_acc,
        'confusion_matrix': cm,
        'predictions': all_preds,
        'labels': all_labels
    }


def print_results(results, class_names):
    """
    í‰ê°€ ê²°ê³¼ ì¶œë ¥

    Args:
        results (dict): í‰ê°€ ê²°ê³¼
        class_names (list): í´ë˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
    """
    print("\n" + "="*60)
    print("Evaluation Results")
    print("="*60)
    print(f"Val Loss: {results['loss']:.4f}")
    print(f"Val Accuracy: {results['accuracy']:.2f}%")

    print("\n" + "-"*60)
    print("Per-class Accuracy:")
    print("-"*60)
    for class_name, stats in results['per_class_acc'].items():
        print(f"  {class_name:8s}: {stats['accuracy']:5.1f}% ({stats['correct']:3d}/{stats['total']:3d})")

    print("\n" + "-"*60)
    print("Confusion Matrix:")
    print("-"*60)
    print("Rows: True labels, Columns: Predicted labels")
    print(f"Classes: {', '.join(class_names)}")
    print()
    cm = results['confusion_matrix']

    # í—¤ë” ì¶œë ¥
    header = "       " + "  ".join([f"{name[:4]:>4s}" for name in class_names])
    print(header)
    print("-" * len(header))

    # ê° í–‰ ì¶œë ¥
    for i, class_name in enumerate(class_names):
        row = f"{class_name[:6]:6s} " + "  ".join([f"{cm[i][j]:4d}" for j in range(len(class_names))])
        print(row)

    print("="*60)


def validate_one_model(model_path: str):
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸ§ª ì—°í•©í•™ìŠµ ìµœì¢… ëª¨ë¸ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    # Device ì„¤ì •
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nğŸ–¥ï¸  ë””ë°”ì´ìŠ¤: {device}")

    # NOTE: ëª¨ë¸ ë¡œë“œ
    print("\n1ï¸âƒ£ ëª¨ë¸ ë¡œë“œ ì¤‘...")
    checkpoint_path = model_path
    model, checkpoint_info = load_model(checkpoint_path, device)

    # 2. ë°ì´í„°ì…‹ ì¤€ë¹„
    print("\n2ï¸âƒ£ ë°ì´í„°ì…‹ ì¤€ë¹„ ì¤‘...")
    val_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    val_dataset = SkinDiseaseDataset(
        data_root='data/validation',
        transform=val_transform
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=32,
        shuffle=False,
        num_workers=0,  # ì¬í˜„ì„±ì„ ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •
        pin_memory=False
    )

    print(f"   âœ… Validation ìƒ˜í”Œ ìˆ˜: {len(val_dataset)}")

    # í´ë˜ìŠ¤ ì´ë¦„ ì¶”ì¶œ
    idx_to_class = {v: k for k, v in val_dataset.class_to_idx.items()}
    class_names = [idx_to_class[i] for i in range(len(idx_to_class))]
    print(f"   âœ… í´ë˜ìŠ¤: {', '.join(class_names)}")

    # 3. í‰ê°€
    print("\n3ï¸âƒ£ ëª¨ë¸ í‰ê°€ ì¤‘...")
    criterion = nn.CrossEntropyLoss()
    results = evaluate(model, val_loader, criterion, device, class_names)

    # 4. ê²°ê³¼ ì¶œë ¥
    print_results(results, class_names)


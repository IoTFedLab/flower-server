"""iot-fed: Flower / PyTorch ì—°í•©í•™ìŠµ ì• í”Œë¦¬ì¼€ì´ì…˜"""

import torch
import torch.nn as nn
import timm
from tqdm import tqdm
from flwr_datasets import FederatedDataset
from flwr_datasets.partitioner import IidPartitioner
from torch.utils.data import DataLoader
from torchvision.transforms import Compose, Normalize, ToTensor, Resize


class Net(nn.Module):
    """í”¼ë¶€ì§ˆí™˜ ë¶„ë¥˜ë¥¼ ìœ„í•œ MobileNetV3-Small ëª¨ë¸ (6ê°œ í´ë˜ìŠ¤)"""

    def __init__(self, num_classes=6, pretrained=False, drop_rate=0.2):
        super(Net, self).__init__()
        # MobileNetV3-Small ëª¨ë¸ ìƒì„±
        self.model = timm.create_model(
            'mobilenetv3_small_100.lamb_in1k',
            pretrained=pretrained,
            num_classes=num_classes,
            drop_rate=drop_rate
        )

    def forward(self, x):
        return self.model(x)


fds = None  # FederatedDataset ìºì‹œ

# MobileNetV3ìš© ë³€í™˜ (224x224 ì…ë ¥ í¬ê¸°)
pytorch_transforms = Compose([
    Resize((224, 224)),
    ToTensor(),
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet í†µê³„
])


def apply_transforms(batch):
    """FederatedDataset íŒŒí‹°ì…˜ì— ë³€í™˜ ì ìš©"""
    batch["img"] = [pytorch_transforms(img) for img in batch["img"]]
    return batch


def load_data(partition_id: int, num_partitions: int, use_cifar10: bool = True, data_root: str = None, val_data_root: str = None):
    """
    ì—°í•©í•™ìŠµì„ ìœ„í•œ ë°ì´í„° ë¡œë“œ

    Args:
        partition_id: í˜„ì¬ íŒŒí‹°ì…˜ ID (CIFAR-10ì—ì„œë§Œ ì‚¬ìš©)
        num_partitions: ì „ì²´ íŒŒí‹°ì…˜ ìˆ˜ (CIFAR-10ì—ì„œë§Œ ì‚¬ìš©)
        use_cifar10: Trueë©´ CIFAR-10 ì‚¬ìš©, Falseë©´ ì»¤ìŠ¤í…€ í”¼ë¶€ì§ˆí™˜ ë°ì´í„°ì…‹ ì‚¬ìš©
        data_root: í›ˆë ¨ ë°ì´í„°ì…‹ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ (use_cifar10=Falseì¼ ë•Œ í•„ìˆ˜)
        val_data_root: ê²€ì¦ ë°ì´í„°ì…‹ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ (use_cifar10=Falseì¼ ë•Œ í•„ìˆ˜)

    Returns:
        (trainloader, valloader) íŠœí”Œ
    """
    if use_cifar10:
        # CIFAR-10 ë°ì´í„° ë¡œë“œ (ì›ë³¸ êµ¬í˜„)
        global fds
        if fds is None:
            partitioner = IidPartitioner(num_partitions=num_partitions)
            fds = FederatedDataset(
                dataset="uoft-cs/cifar10",
                partitioners={"train": partitioner},
            )
        partition = fds.load_partition(partition_id)
        partition_train_test = partition.train_test_split(test_size=0.2, seed=42)
        partition_train_test = partition_train_test.with_transform(apply_transforms)
        trainloader = DataLoader(partition_train_test["train"], batch_size=32, shuffle=True)
        valloader = DataLoader(partition_train_test["test"], batch_size=32)
    else:
        # ì»¤ìŠ¤í…€ í”¼ë¶€ì§ˆí™˜ ë°ì´í„° ë¡œë“œ (ì´ë¯¸ train/val ë¶„ë¦¬ëœ ìƒíƒœ)
        from iot_fed.dataset import load_skin_disease_data
        if data_root is None or val_data_root is None:
            raise ValueError("use_cifar10=Falseì¼ ë•Œ data_rootì™€ val_data_rootëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤")
        trainloader, valloader = load_skin_disease_data(
            data_root=data_root,
            val_data_root=val_data_root,
            partition_id=partition_id,
            num_partitions=num_partitions,
            batch_size=32
        )

    return trainloader, valloader


def train(net, trainloader, epochs, lr, device):
    """í•™ìŠµ ë°ì´í„°ì…‹ìœ¼ë¡œ ëª¨ë¸ í›ˆë ¨"""
    net.to(device)  # GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ ëª¨ë¸ì„ GPUë¡œ ì´ë™
    criterion = torch.nn.CrossEntropyLoss().to(device)
    optimizer = torch.optim.AdamW(net.parameters(), lr=lr, weight_decay=0.01)
    net.train()
    running_loss = 0.0

    # ì—í­ë³„ ì§„í–‰ í‘œì‹œ
    for epoch in range(epochs):
        epoch_loss = 0.0

        # ë°°ì¹˜ë³„ ì§„í–‰ í‘œì‹œ
        with tqdm(trainloader, desc=f"ğŸ“š Epoch {epoch+1}/{epochs}", unit="batch", leave=False) as pbar:
            for batch in pbar:
                # dict (CIFAR-10)ì™€ tuple (ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹) í˜•ì‹ ëª¨ë‘ ì²˜ë¦¬
                if isinstance(batch, dict):
                    images = batch["img"].to(device)
                    labels = batch["label"].to(device)
                else:
                    images, labels = batch
                    images = images.to(device)
                    labels = labels.to(device)

                optimizer.zero_grad()
                loss = criterion(net(images), labels)
                loss.backward()
                optimizer.step()

                batch_loss = loss.item()
                running_loss += batch_loss
                epoch_loss += batch_loss

                # ì‹¤ì‹œê°„ loss í‘œì‹œ
                pbar.set_postfix({'loss': f'{batch_loss:.4f}'})

        # ì—í­ ì™„ë£Œ í›„ í‰ê·  loss ì¶œë ¥
        avg_epoch_loss = epoch_loss / len(trainloader)
        print(f"   âœ“ Epoch {epoch+1}/{epochs} ì™„ë£Œ - Avg Loss: {avg_epoch_loss:.4f}")

    avg_trainloss = running_loss / (len(trainloader) * epochs)
    return avg_trainloss


def test(net, testloader, device):
    """í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ìœ¼ë¡œ ëª¨ë¸ ê²€ì¦"""
    net.to(device)
    criterion = torch.nn.CrossEntropyLoss()
    correct, loss = 0, 0.0

    with torch.no_grad():
        # í‰ê°€ ì§„í–‰ í‘œì‹œ
        with tqdm(testloader, desc="ğŸ” í‰ê°€ ì¤‘", unit="batch", leave=False) as pbar:
            for batch in pbar:
                # dict (CIFAR-10)ì™€ tuple (ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹) í˜•ì‹ ëª¨ë‘ ì²˜ë¦¬
                if isinstance(batch, dict):
                    images = batch["img"].to(device)
                    labels = batch["label"].to(device)
                else:
                    images, labels = batch
                    images = images.to(device)
                    labels = labels.to(device)

                outputs = net(images)
                batch_loss = criterion(outputs, labels).item()
                loss += batch_loss
                batch_correct = (torch.max(outputs.data, 1)[1] == labels).sum().item()
                correct += batch_correct

                # ì‹¤ì‹œê°„ ì •í™•ë„ í‘œì‹œ
                current_acc = correct / ((pbar.n + 1) * len(labels))
                pbar.set_postfix({'acc': f'{current_acc:.4f}', 'loss': f'{batch_loss:.4f}'})

    accuracy = correct / len(testloader.dataset)
    loss = loss / len(testloader)
    print(f"   âœ“ í‰ê°€ ì™„ë£Œ - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}")
    return loss, accuracy
